library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Short term rate')] # Should I scale?
# c1[,2] <- c1[,2]*1e5
m3 <- arima(c3, order=c(0,0,0), xreg=c1, include.mean=F, method='ML')
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Short term rate')] # Should I scale?
# c1[,2] <- c1[,2]*1e5
m3 <- arima(c3, order=c(1,0,0), xreg=c1, include.mean=F, method='ML')
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Short term rate')] # Should I scale?
# c1[,2] <- c1[,2]*1e5
m3 <- arima(c3, order=c(1,0,0), xreg=c1, include.mean=F, method='ML')
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Short term rate')] # Should I scale?
# c1[,2] <- c1[,2]*1e5
m3 <- arima(c3, order=c(4,0,0), xreg=c1, include.mean=F, method='ML')
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Short term rate')] # Should I scale?
# c1[,2] <- c1[,2]*1e5
m3 <- arima(c3, order=c(1,0,0), xreg=c1, include.mean=F, method='ML')
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Long term rate')] # Not necessary to scale, because `optim` does it automatically
m3 <- arima(c3, order=c(1,0,0), xreg=c1, include.mean=F, method='ML') # include.mean=FALSE, forcing the intercept to be zero
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Short term rate')] # Not necessary to scale, because `optim` does it automatically
m3 <- arima(c3, order=c(1,0,0), xreg=c1, include.mean=F, method='ML') # include.mean=FALSE, forcing the intercept to be zero
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Long term rate')] # Not necessary to scale, because `optim` does it automatically
m3 <- arima(c3, order=c(1,0,0), xreg=c1, include.mean=F, method='ML') # include.mean=FALSE, forcing the intercept to be zero
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Short term rate')] # Not necessary to scale, because `optim` does it automatically
m3 <- arima(c3, order=c(1,0,0), xreg=c1, include.mean=F, method='ML') # include.mean=FALSE, forcing the intercept to be zero
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
knitr::opts_chunk$set(echo = TRUE)
source('Functions_2.R')
library(tidyverse)
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
data_real <- read_delim('Session 10. Ibex.csv', delim = ';', locale = locale(decimal_mark = ','), col_names = c('Week', 'IBEX','Exchange rate', 'Short term rate', 'Long term rate'), skip=1)
data_real['Week'] <- NULL
library("PerformanceAnalytics")
chart.Correlation(data_real, histogram=TRUE, pch=19)
m1 <- glm(formula = IBEX ~ -1 + `Exchange rate` + `Short term rate` + `Long term rate`, family = gaussian(link = "identity"), data = data_real)
library(MASS)
m2 <- m1 %>%
stepAIC(trace = TRUE)
summary(m2)
plot_ts(m2$residuals)
formal_white_noise(m2$residuals, lag=1)
# IBEX ~ -1 + `Exchange rate <U+FFFD>/$` + `Short term rate` + `Long term rate`,
c3 <- data_real[, 'IBEX']
c1 <- data_real[, c('Exchange rate', 'Short term rate')] # Not necessary to scale, because `optim` does it automatically
m3 <- arima(c3, order=c(1,0,0), xreg=c1, include.mean=F, method='ML') # include.mean=FALSE, forcing the intercept to be zero
m3
confint(m3)
plot_ts(m3$residuals)
formal_white_noise(m3$residuals, lag=1)
library(ggplot2)
scaleFactor <- max(mtcars$cyl) / max(mtcars$hp)
ggplot(mtcars, aes(x=disp)) +
geom_smooth(aes(y=cyl), method="loess", col="blue") +
geom_smooth(aes(y=hp * scaleFactor), method="loess", col="red") +
scale_y_continuous(name="cyl", sec.axis=sec_axis(~./scaleFactor, name="hp")) +
theme(
axis.title.y.left=element_text(color="blue"),
axis.text.y.left=element_text(color="blue"),
axis.title.y.right=element_text(color="red"),
axis.text.y.right=element_text(color="red")
)
scaleFactor
library(gapminder)
library(tidyverse)
library(ggplot2)
data("gapminder")
data_sort <- gapminder %>%
group_by(continent) %>%
summarise(pop=sum(pop)) %>%
arrange(desc(pop))
data <- gapminder %>%
group_by(continent, year) %>%
summarise(pop=sum(pop)/1e9, `gdpPercap in th`=mean(gdpPercap)/1e3) %>%
mutate(continent=factor(continent, levels=data_sort[['continent']]))
data
data <- gapminder %>%
group_by(continent, year) %>%
summarise(pop=sum(pop)/1e9, `gdpPercap in th`=mean(gdpPercap)/1e3) %>%
mutate(continent=factor(continent, levels=data_sort[['continent']])) %>%
mutate(pop=pop/pop[1])
data
ggplot(data) +
geom_point(aes(year, pop, color=continent, size=`gdpPercap in th`, alpha=0.3)) +
scale_size_continuous(range = c(0.1, 20)) +
scale_alpha(guide = 'none') +
# facet_wrap(continent~., nrow=5) +
ylab('Population in billions') + xlab('Year')
daa$pop[1]
data$pop[1]
data$pop[1,]
data <- gapminder %>%
group_by(continent, year) %>%
summarise(pop=sum(pop)/1e9, `gdpPercap in th`=mean(gdpPercap)/1e3) %>%
mutate(continent=factor(continent, levels=data_sort[['continent']]))
data <- gapminder %>%
group_by(continent, year) %>%
summarise(pop=sum(pop)/1e9, `gdpPercap in th`=mean(gdpPercap)/1e3) %>%
mutate(continent=factor(continent, levels=data_sort[['continent']]))
data$pop[1,]
data$pop[1]
data$pop
data <- gapminder %>%
group_by(continent, year) %>%
summarise(pop=sum(pop)/1e9, `gdpPercap in th`=mean(gdpPercap)/1e3) %>%
mutate(continent=factor(continent, levels=data_sort[['continent']]))
data
data <- gapminder %>%
group_by(continent, year) %>%
summarise(pop=sum(pop)/1e9, `gdpPercap in th`=mean(gdpPercap)/1e3) %>%
mutate(continent=factor(continent, levels=data_sort[['continent']]))
data
data2 <- data %>%
group_by(continent, year) %>%
filter(year=min(year))
data2 <- data %>%
group_by(continent, year) %>%
filter(year==min(year))
data2
data2 <- data %>%
group_by(continent, year) %>%
slice(which.min(year))
data2
data2 <- data %>%
group_by(continent) %>%
slice(which.min(year))
data2
data %>%
inner_join(data2, by=`continent`)
data %>%
inner_join(data2, by='continent')
data3 <- data %>%
inner_join(data2, by='continent') %>%
mutate(pop_increase = pop/pop.y)
data3 <- data %>%
inner_join(data2, by='continent') %>%
mutate(pop_increase = pop.x/pop.y)
data3
ggplot(data3) +
geom_point(aes(year, pop_increase, color=continent, size=`gdpPercap in th`, alpha=0.3)) +
scale_size_continuous(range = c(0.1, 20)) +
scale_alpha(guide = 'none') +
# facet_wrap(continent~., nrow=5) +
ylab('Population increase') + xlab('Year')
ggplot(data3) +
geom_point(aes(year.x, pop_increase, color=continent, size=`gdpPercap in th`, alpha=0.3)) +
scale_size_continuous(range = c(0.1, 20)) +
scale_alpha(guide = 'none') +
# facet_wrap(continent~., nrow=5) +
ylab('Population increase') + xlab('Year')
data3
ggplot(data3) +
geom_point(aes(year.x, pop_increase, color=continent, size=`gdpPercap in th.x`, alpha=0.3)) +
scale_size_continuous(range = c(0.1, 20)) +
scale_alpha(guide = 'none') +
# facet_wrap(continent~., nrow=5) +
ylab('Population increase') + xlab('Year')
data("gapminder")
data_sort <- gapminder %>%
group_by(continent) %>%
summarise(pop=sum(pop)) %>%
arrange(desc(pop))
data <- gapminder %>%
group_by(continent, year) %>%
summarise(pop=sum(pop)/1e9, `gdpPercap in th`=mean(gdpPercap)/1e3) %>%
mutate(continent=factor(continent, levels=data_sort[['continent']]))
# https://stackoverflow.com/a/21622182
data2 <- data %>%
group_by(continent) %>%
slice(which.min(year))
data3 <- data %>%
inner_join(data2, by='continent') %>%
mutate(pop_increase = pop.x/pop.y)
ggplot(data3) +
geom_point(aes(year.x, pop_increase, color=continent, size=`gdpPercap in th.x`, alpha=0.3)) +
scale_size_continuous(range = c(0.1, 20)) +
scale_alpha(guide = 'none') +
# facet_wrap(continent~., nrow=5) +
ylab('Population increase') + xlab('Year')
ggplot(data3) +
geom_point(aes(year.x, pop_increase, color=continent, size=`gdpPercap in th.x`, alpha=0.2)) +
scale_size_continuous(range = c(0.1, 20)) +
scale_alpha(guide = 'none') +
ylab('Population increase') + xlab('Year')
shiny::runApp('C:/Users/R100983/OneDrive/GMBD/2020-01-10 - TERM 1/STATISTICAL PROGRAMMING - R (MBD-EN-BL2020J-1_32R369_316435)/Group assignment/GitHub/gmbd_r/!Delivery/Shiny')
# General purpose
library(tidyverse)
library(data.table)
library(lubridate)
# Shiny
library(shiny)
# Visualization
library(ggplot2)
library(ggpubr)
# Mapping
library(leaflet)
library(leaflet.extras)
library(leafpop)
library(htmltools)
# Spatial
library(sp)
library(rgdal)
library(rgeos)
runApp('C:/Users/R100983/OneDrive/GMBD/2020-01-10 - TERM 1/STATISTICAL PROGRAMMING - R (MBD-EN-BL2020J-1_32R369_316435)/Group assignment/GitHub/gmbd_r/!Delivery/Shiny')
setwd("C:/Users/juanb/OneDrive/GMBD/2020-01-10 - TERM 1/STATISTICAL PROGRAMMING - R (MBD-EN-BL2020J-1_32R369_316435)/Group assignment/GitHub/gmbd_r/!Delivery/Shiny")
setwd("C:/Users/R100983/OneDrive/GMBD/2020-01-10 - TERM 1/STATISTICAL PROGRAMMING - R (MBD-EN-BL2020J-1_32R369_316435)/Group assignment/GitHub/gmbd_r/!Delivery/Shiny")
runApp()
# GMBD 2020 Intake
# Group E
#   Juan Pedro Bretti Mandarano
#   Nicolas Greull
#   Zhaoxue Li
#   Gauchet van Antwerpen
#   Asad Umar
# The applications takes a few minutes to load
## Libraries ----
# General purpose
library(tidyverse)
library(data.table)
library(lubridate)
# Shiny
library(shiny)
# Visualization
library(ggplot2)
library(ggpubr)
# Mapping
library(leaflet)
library(leaflet.extras)
library(leafpop)
library(htmltools)
# Spatial
library(sp)
library(rgdal)
library(rgeos)
## Load data ----
setwd("C:/Users/R100983/OneDrive/GMBD/2020-01-10 - TERM 1/STATISTICAL PROGRAMMING - R (MBD-EN-BL2020J-1_32R369_316435)/Group assignment/GitHub/gmbd_r/!Delivery/Shiny")
data_solar <- readRDS(file = file.path('data', 'solar_dataset.RData'))
data_station <- fread(file = file.path('data', 'station_info.csv'))
## Transform data ----
# Source dataset
data_solar <- data_solar[j = Date2 := as.Date(x = Date, format = "%Y%m%d")]
# Add date conversions
data_solar <- data_solar %>%
mutate(Year = year(Date2),
Month = month(Date2, label = TRUE),
Year_Month = format(Date2, '%Y-%m'),
Day = day(Date2),
Day_Of_Year = yday(Date2),
Day_Of_Week = wday(Date2, label = TRUE, week_start = 1),
Weekend = ifelse(Day_Of_Week %in% c('Sat', 'Sun'), 'Weekend', 'Workday'),
Days_Since_Origin = time_length(interval(origin, Date2), unit = 'day')) %>%
as.data.table(.)
# Columns defined from the enunciate
data_solar_col_produ <- colnames(data_solar)[2:99]
data_solar_col_predi <- colnames(data_solar)[100:456]
data_solar_col_dates <- setdiff(colnames(data_solar), c(data_solar_col_produ, data_solar_col_predi))
# Split train and test set
data_solar_train <- data_solar[i = 1:5113]
# data_solar_test <- data_solar[i = 5114:nrow(data_solar), j = .SD, .SDcols = c(data_solar_col_dates, data_solar_col_predi)]
# Positions for map ----
data_position <- data_solar_train %>%
select(-all_of(data_solar_col_predi)) %>%
pivot_longer(cols = all_of(data_solar_col_produ), names_to = 'WeatherStation', values_to = 'Value') %>%
group_by(WeatherStation) %>%
summarise(ValueMean = tail(Value, 1)) %>%
left_join(data_station, by = c('WeatherStation' = 'stid'))
# Labels for the map ----
data_position$Label <-
paste('<strong>', data_position$WeatherStation, '</strong>', '<br/>',
'Elevation:', round(data_position$elon, 0), 'm', '<br/>',
'Last production:', round(data_position$ValueMean/1e6, 1), 'million') %>%
lapply(HTML)
# Plots for addPopupGraphs ----
# https://www.datanovia.com/en/lessons/combine-multiple-ggplots-into-a-figure/
plot_addPopupGraphs <- function(data){
p_all <- data %>%
ggplot() +
geom_smooth(aes(x = Date2, y = Value/1e6)) +
labs(x = 'Date', y = 'Production in million')
p_year <- data %>%
ggplot(aes(x = Year, y = Value/1e6, group = Year)) +
geom_boxplot() +
labs(x = 'Year', y = 'Production in million') +
ggpubr::rotate_x_text()
p_month <- data %>%
ggplot(aes(x = Month, y = Value/1e6)) +
geom_boxplot() +
labs(x = 'Month', y = '') +
ggpubr::rotate_x_text()
p_day_of_week <- data %>%
ggplot(aes(x = Day_Of_Week, y = Value/1e6, fill = Weekend)) +
geom_boxplot() +
labs(x = 'Day of the week', y = '') +
theme(legend.position = "none") +
scale_fill_manual(values=c("gray80", "white")) +
ggpubr::rotate_x_text()
plot <- ggarrange(
p_all,
ggarrange(p_year, p_month, p_day_of_week, ncol = 3),
nrow = 2
)
plot <- annotate_figure(plot, top = text_grob(unique(data$WeatherStation), face = "bold", size = 14))
return(plot)
}
# Create all the plots, takes some time ----
# The following code is commented, to speed up the loading process of the Shiny app.
# The output of this chunk, is saved into the object 'data_plot.rds'
data_plot <- data_solar_train %>%
dplyr::select(all_of(c(data_solar_col_dates, data_solar_col_produ))) %>%
pivot_longer(cols = all_of(data_solar_col_produ), names_to = 'WeatherStation', values_to = 'Value') %>%
# filter(WeatherStation %in% data_solar_col_produ[1:2]) %>%
group_by(WeatherStation) %>%
do(
plots = plot_addPopupGraphs(.)
)
data_plot[[2]]
saveRDS(data_plot, file.path('GroupE', 'storage', 'data_plot.rds'))
saveRDS(data_plot, file.path('storage', 'data_plot.rds'))
runApp()
